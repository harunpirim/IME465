{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quality Control - Manufacturing Defect Prediction\n",
        "\n",
        "This notebook demonstrates machine learning for predicting manufacturing defects in steel plates.\n",
  "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harunpirim/IME465/blob/main/quality_control/quality_control.ipynb)",
        "\n",
        "## Objectives:\n",
        "1. Load and explore the Steel Plates Faults dataset\n",
        "2. Perform comprehensive EDA\n",
        "3. Engineer features to improve model performance\n",
        "4. Build and compare multiple ML models\n",
        "5. Evaluate and interpret results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
        "                             f1_score, roc_auc_score, confusion_matrix, \n",
        "                             classification_report, roc_curve)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading\n",
        "\n",
        "We'll use the Steel Plates Faults dataset. This dataset contains 27 features describing steel plate attributes and 7 types of faults.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "# Note: In practice, you would download this from UCI ML Repository\n",
        "# For this tutorial, we'll create a synthetic dataset based on the real one\n",
        "# URL: https://archive.ics.uci.edu/ml/datasets/Steel+Plates+Faults\n",
        "\n",
        "# Create synthetic data that mimics the Steel Plates Faults dataset\n",
        "np.random.seed(42)\n",
        "n_samples = 1941\n",
        "\n",
        "# Generate features similar to the real dataset\n",
        "data = {\n",
        "    'X_Minimum': np.random.uniform(0, 200, n_samples),\n",
        "    'X_Maximum': np.random.uniform(0, 200, n_samples),\n",
        "    'Y_Minimum': np.random.uniform(0, 200, n_samples),\n",
        "    'Y_Maximum': np.random.uniform(0, 200, n_samples),\n",
        "    'Pixels_Areas': np.random.uniform(100, 10000, n_samples),\n",
        "    'X_Perimeter': np.random.uniform(50, 500, n_samples),\n",
        "    'Y_Perimeter': np.random.uniform(50, 500, n_samples),\n",
        "    'Sum_of_Luminosity': np.random.uniform(1000, 100000, n_samples),\n",
        "    'Minimum_of_Luminosity': np.random.uniform(0, 255, n_samples),\n",
        "    'Maximum_of_Luminosity': np.random.uniform(0, 255, n_samples),\n",
        "    'Length_of_Conveyer': np.random.uniform(100, 1000, n_samples),\n",
        "    'TypeOfSteel_A300': np.random.choice([0, 1], n_samples),\n",
        "    'TypeOfSteel_A400': np.random.choice([0, 1], n_samples),\n",
        "    'Steel_Plate_Thickness': np.random.uniform(0.1, 5.0, n_samples),\n",
        "    'Edges_Index': np.random.uniform(0, 1, n_samples),\n",
        "    'Empty_Index': np.random.uniform(0, 1, n_samples),\n",
        "    'Square_Index': np.random.uniform(0, 1, n_samples),\n",
        "    'Outside_X_Index': np.random.uniform(0, 1, n_samples),\n",
        "    'Edges_Y_Index': np.random.uniform(0, 1, n_samples),\n",
        "    'Edges_X_Index': np.random.uniform(0, 1, n_samples),\n",
        "    'LogOfAreas': np.random.uniform(2, 10, n_samples),\n",
        "    'Log_X_Index': np.random.uniform(0, 5, n_samples),\n",
        "    'Log_Y_Index': np.random.uniform(0, 5, n_samples),\n",
        "    'Orientation_Index': np.random.uniform(0, 1, n_samples),\n",
        "    'Luminosity_Index': np.random.uniform(0, 1, n_samples),\n",
        "    'SigmoidOfAreas': np.random.uniform(0, 1, n_samples),\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create target variable: fault (1) or no fault (0)\n",
        "# Introduce some relationships to make it realistic\n",
        "fault_prob = (\n",
        "    0.1 + \n",
        "    0.3 * (df['Edges_Index'] > 0.7) +\n",
        "    0.2 * (df['Empty_Index'] > 0.6) +\n",
        "    0.2 * (df['Steel_Plate_Thickness'] < 0.5) +\n",
        "    0.1 * (df['Luminosity_Index'] < 0.3) +\n",
        "    np.random.normal(0, 0.1, n_samples)\n",
        ")\n",
        "df['Fault'] = (fault_prob > 0.4).astype(int)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 Basic Information\n",
        "print(\"Dataset Info:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\nMissing values:\")\n",
        "print(df.isnull().sum().sum())\n",
        "print(f\"\\nData types:\")\n",
        "print(df.dtypes.value_counts())\n",
        "print(f\"\\nBasic statistics:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.2 Target Variable Distribution\n",
        "print(\"Target Variable Distribution:\")\n",
        "print(\"=\" * 50)\n",
        "print(df['Fault'].value_counts())\n",
        "print(f\"\\nPercentage:\")\n",
        "print(df['Fault'].value_counts(normalize=True) * 100)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "df['Fault'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "plt.title('Distribution of Fault vs No Fault', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Fault (0=No Fault, 1=Fault)', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.3 Feature Distributions\n",
        "# Select key features for visualization\n",
        "key_features = ['X_Minimum', 'X_Maximum', 'Steel_Plate_Thickness', \n",
        "                'Edges_Index', 'Empty_Index', 'Luminosity_Index']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, feature in enumerate(key_features):\n",
        "    axes[i].hist(df[feature], bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[i].set_title(f'Distribution of {feature}', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel(feature, fontsize=10)\n",
        "    axes[i].set_ylabel('Frequency', fontsize=10)\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.4 Correlation Analysis\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Plot correlation matrix\n",
        "plt.figure(figsize=(14, 12))\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=False, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix of Features', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find highly correlated features\n",
        "high_corr_pairs = []\n",
        "for i in range(len(corr_matrix.columns)):\n",
        "    for j in range(i+1, len(corr_matrix.columns)):\n",
        "        if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
        "            high_corr_pairs.append((\n",
        "                corr_matrix.columns[i], \n",
        "                corr_matrix.columns[j], \n",
        "                corr_matrix.iloc[i, j]\n",
        "            ))\n",
        "\n",
        "print(\"\\nHighly correlated feature pairs (|correlation| > 0.8):\")\n",
        "for pair in high_corr_pairs[:10]:  # Show first 10\n",
        "    print(f\"{pair[0]} - {pair[1]}: {pair[2]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.5 Feature-Target Relationships\n",
        "# Compare feature distributions by target class\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, feature in enumerate(key_features):\n",
        "    df[df['Fault'] == 0][feature].hist(ax=axes[i], bins=30, alpha=0.6, \n",
        "                                        label='No Fault', color='skyblue')\n",
        "    df[df['Fault'] == 1][feature].hist(ax=axes[i], bins=30, alpha=0.6, \n",
        "                                        label='Fault', color='salmon')\n",
        "    axes[i].set_title(f'{feature} by Fault Status', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel(feature, fontsize=10)\n",
        "    axes[i].set_ylabel('Frequency', fontsize=10)\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering\n",
        "\n",
        "Based on our EDA, we'll:\n",
        "1. Handle missing values (if any)\n",
        "2. Create derived features\n",
        "3. Remove highly correlated features\n",
        "4. Scale features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 Create a copy for feature engineering\n",
        "df_processed = df.copy()\n",
        "\n",
        "# 3.2 Create derived features\n",
        "# Area feature\n",
        "df_processed['Area'] = (df_processed['X_Maximum'] - df_processed['X_Minimum']) * \\\n",
        "                       (df_processed['Y_Maximum'] - df_processed['Y_Minimum'])\n",
        "\n",
        "# Aspect ratio\n",
        "df_processed['Aspect_Ratio'] = (df_processed['X_Maximum'] - df_processed['X_Minimum']) / \\\n",
        "                                (df_processed['Y_Maximum'] - df_processed['Y_Minimum'] + 1e-6)\n",
        "\n",
        "# Perimeter ratio\n",
        "df_processed['Perimeter_Ratio'] = df_processed['X_Perimeter'] / (df_processed['Y_Perimeter'] + 1e-6)\n",
        "\n",
        "# Luminosity range\n",
        "df_processed['Luminosity_Range'] = df_processed['Maximum_of_Luminosity'] - \\\n",
        "                                    df_processed['Minimum_of_Luminosity']\n",
        "\n",
        "# Normalized area\n",
        "df_processed['Normalized_Area'] = df_processed['Pixels_Areas'] / (df_processed['Area'] + 1e-6)\n",
        "\n",
        "print(\"Created derived features:\")\n",
        "print(\"- Area\")\n",
        "print(\"- Aspect_Ratio\")\n",
        "print(\"- Perimeter_Ratio\")\n",
        "print(\"- Luminosity_Range\")\n",
        "print(\"- Normalized_Area\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.3 Remove highly correlated features\n",
        "# We'll keep one feature from each highly correlated pair\n",
        "features_to_remove = []\n",
        "for pair in high_corr_pairs:\n",
        "    if pair[0] not in features_to_remove and pair[1] not in features_to_remove:\n",
        "        # Keep the feature with higher correlation to target\n",
        "        corr1 = abs(df_processed[pair[0]].corr(df_processed['Fault']))\n",
        "        corr2 = abs(df_processed[pair[1]].corr(df_processed['Fault']))\n",
        "        if corr1 < corr2:\n",
        "            features_to_remove.append(pair[0])\n",
        "        else:\n",
        "            features_to_remove.append(pair[1])\n",
        "\n",
        "print(f\"Features to remove due to high correlation: {features_to_remove[:5]}\")\n",
        "\n",
        "# For this tutorial, we'll keep all features but note this for production\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.4 Prepare features and target\n",
        "# Separate features and target\n",
        "X = df_processed.drop('Fault', axis=1)\n",
        "y = df_processed['Fault']\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n",
        "print(f\"\\nTraining set target distribution:\")\n",
        "print(y_train.value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.5 Feature Scaling\n",
        "# Scale features for algorithms that are sensitive to scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame for easier handling\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(\"Features scaled using StandardScaler\")\n",
        "print(f\"Scaled training set mean: {X_train_scaled.mean().mean():.6f}\")\n",
        "print(f\"Scaled training set std: {X_train_scaled.std().mean():.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Machine Learning Models\n",
        "\n",
        "We'll train and compare multiple models:\n",
        "1. Logistic Regression (baseline)\n",
        "2. Random Forest\n",
        "3. Support Vector Machine\n",
        "4. Gradient Boosting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 Logistic Regression\n",
        "print(\"Training Logistic Regression...\")\n",
        "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "y_pred_proba_lr = lr.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nLogistic Regression Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred_lr):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_lr):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.2 Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nRandom Forest Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_rf):.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.3 Support Vector Machine\n",
        "print(\"Training Support Vector Machine...\")\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "y_pred_proba_svm = svm.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nSVM Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_svm):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_svm):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred_svm):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_svm):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.4 Gradient Boosting\n",
        "print(\"Training Gradient Boosting...\")\n",
        "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "y_pred_proba_gb = gb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nGradient Boosting Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gb):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_gb):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_gb):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred_gb):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_gb):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Comparison and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1 Compare all models\n",
        "models = {\n",
        "    'Logistic Regression': (y_pred_lr, y_pred_proba_lr),\n",
        "    'Random Forest': (y_pred_rf, y_pred_proba_rf),\n",
        "    'SVM': (y_pred_svm, y_pred_proba_svm),\n",
        "    'Gradient Boosting': (y_pred_gb, y_pred_proba_gb)\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, (y_pred, y_pred_proba) in models.items():\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred),\n",
        "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Model Comparison:\")\n",
        "print(\"=\" * 80)\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.2 Visualize model comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Metrics comparison\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.2\n",
        "\n",
        "for i, (name, _) in enumerate(models.items()):\n",
        "    values = [results_df[results_df['Model'] == name][metric].values[0] for metric in metrics]\n",
        "    axes[0].bar(x + i*width, values, width, label=name)\n",
        "\n",
        "axes[0].set_xlabel('Metrics', fontsize=12)\n",
        "axes[0].set_ylabel('Score', fontsize=12)\n",
        "axes[0].set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xticks(x + width * 1.5)\n",
        "axes[0].set_xticklabels(metrics)\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "axes[0].set_ylim([0, 1.1])\n",
        "\n",
        "# ROC Curves\n",
        "for name, (_, y_pred_proba) in models.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    axes[1].plot(fpr, tpr, label=f'{name} (AUC = {roc_auc_score(y_test, y_pred_proba):.3f})')\n",
        "\n",
        "axes[1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
        "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
        "axes[1].set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.3 Confusion Matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, (name, (y_pred, _)) in enumerate(models.items()):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
        "                xticklabels=['No Fault', 'Fault'],\n",
        "                yticklabels=['No Fault', 'Fault'])\n",
        "    axes[i].set_title(f'{name}\\nAccuracy: {accuracy_score(y_test, y_pred):.3f}', \n",
        "                      fontsize=12, fontweight='bold')\n",
        "    axes[i].set_ylabel('True Label', fontsize=10)\n",
        "    axes[i].set_xlabel('Predicted Label', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Importance Analysis\n",
        "\n",
        "Understanding which features are most important helps in:\n",
        "- Identifying key quality indicators\n",
        "- Improving manufacturing processes\n",
        "- Reducing feature dimensionality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize feature importance from Random Forest\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = feature_importance.head(15)\n",
        "plt.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
        "plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "plt.xlabel('Importance', fontsize=12)\n",
        "plt.title('Top 15 Most Important Features (Random Forest)', fontsize=14, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary and Conclusions\n",
        "\n",
        "### Key Findings:\n",
        "1. **Best Model**: Based on the evaluation metrics, [model name] performs best\n",
        "2. **Important Features**: [List top features]\n",
        "3. **Business Impact**: The model can help identify defective products early, reducing waste and improving quality\n",
        "\n",
        "### Next Steps:\n",
        "- Collect more data to improve model performance\n",
        "- Deploy model for real-time quality control\n",
        "- Monitor model performance over time\n",
        "- Consider ensemble methods for better accuracy\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
