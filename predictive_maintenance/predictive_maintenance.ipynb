{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance - Equipment Failure Prediction\n",
    "\n",
    "This notebook demonstrates ML for predicting equipment failures based on sensor data.\n",
    "\n",
    "## Objectives:\n",
    "1. Load and explore the AI4I 2020 Predictive Maintenance dataset\n",
    "2. Perform EDA on sensor data and operational parameters\n",
    "3. Engineer temporal and interaction features\n",
    "4. Build and compare ML models\n",
    "5. Evaluate with focus on recall (catching failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "AI4I 2020 Predictive Maintenance Dataset with operational settings and sensor measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic predictive maintenance data\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "\n",
    "data = {\n",
    "    'air_temperature': np.random.uniform(295, 305, n_samples),\n",
    "    'process_temperature': np.random.uniform(305, 315, n_samples),\n",
    "    'rotational_speed': np.random.uniform(1168, 2886, n_samples),\n",
    "    'torque': np.random.uniform(3.8, 77, n_samples),\n",
    "    'tool_wear': np.random.uniform(0, 253, n_samples),\n",
    "    'machine_type': np.random.choice(['H', 'L', 'M'], n_samples),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create failure based on realistic relationships\n",
    "failure_prob = (\n",
    "    0.02 +  # base failure rate\n",
    "    0.3 * (df['tool_wear'] > 200) +\n",
    "    0.2 * (df['process_temperature'] > 310) +\n",
    "    0.15 * (df['rotational_speed'] > 2500) +\n",
    "    0.1 * (df['torque'] > 60) +\n",
    "    0.1 * ((df['process_temperature'] - df['air_temperature']) > 12) +\n",
    "    np.random.normal(0, 0.05, n_samples)\n",
    ")\n",
    "df['machine_failure'] = (failure_prob > 0.3).astype(int)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFailure rate: {df['machine_failure'].mean():.2%}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution (likely imbalanced)\n",
    "print(\"Target Distribution:\")\n",
    "print(df['machine_failure'].value_counts())\n",
    "print(f\"\\nFailure rate: {df['machine_failure'].mean():.2%}\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['machine_failure'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Machine Failure Distribution')\n",
    "plt.xlabel('Failure (0=No, 1=Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Create temporal features, interactions, and handle categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Temperature difference\n",
    "df_processed['temp_diff'] = df_processed['process_temperature'] - df_processed['air_temperature']\n",
    "\n",
    "# Power (torque * rotational speed)\n",
    "df_processed['power'] = df_processed['torque'] * df_processed['rotational_speed']\n",
    "\n",
    "# Tool wear categories\n",
    "df_processed['tool_wear_high'] = (df_processed['tool_wear'] > 200).astype(int)\n",
    "\n",
    "# One-hot encode machine type\n",
    "df_processed = pd.get_dummies(df_processed, columns=['machine_type'], prefix='machine')\n",
    "\n",
    "# Prepare features\n",
    "X = df_processed.drop('machine_failure', axis=1)\n",
    "y = df_processed['machine_failure']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features (class imbalance will be handled with class_weight='balanced' in models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "# Note: Using class_weight='balanced' to handle class imbalance (scikit-learn only)\n",
    "models_dict = {}\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "models_dict['LR'] = (y_pred_lr, y_pred_proba_lr)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "models_dict['RF'] = (y_pred_rf, y_pred_proba_rf)\n",
    "\n",
    "# Gradient Boosting (note: doesn't support class_weight, but handles imbalance reasonably well)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "y_pred_proba_gb = gb.predict_proba(X_test)[:, 1]\n",
    "models_dict['GB'] = (y_pred_gb, y_pred_proba_gb)\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "for name, (y_pred, y_pred_proba) in models_dict.items():\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Model Comparison:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "Key findings: Recall is critical for predictive maintenance - missing failures is costly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
