{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthcare - Heart Disease Prediction\n",
    "\n",
    "This notebook demonstrates machine learning for predicting heart disease based on patient characteristics and medical measurements.\n",
    "\n",
    "## Objectives:\n",
    "1. Load and explore the Heart Disease UCI dataset\n",
    "2. Perform comprehensive EDA with clinical context\n",
    "3. Engineer features based on medical knowledge\n",
    "4. Build and compare multiple ML models\n",
    "5. Evaluate and interpret results in clinical context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, roc_curve)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "We'll use the Heart Disease UCI dataset. This dataset contains 14 attributes including demographics, medical history, and test results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Note: In practice, download from UCI ML Repository\n",
    "# URL: https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 303\n",
    "\n",
    "data = {\n",
    "    'age': np.random.randint(29, 78, n_samples),\n",
    "    'sex': np.random.choice([0, 1], n_samples),\n",
    "    'cp': np.random.choice([0, 1, 2, 3], n_samples),\n",
    "    'trestbps': np.random.randint(94, 200, n_samples),\n",
    "    'chol': np.random.randint(126, 564, n_samples),\n",
    "    'fbs': np.random.choice([0, 1], n_samples),\n",
    "    'restecg': np.random.choice([0, 1, 2], n_samples),\n",
    "    'thalach': np.random.randint(71, 202, n_samples),\n",
    "    'exang': np.random.choice([0, 1], n_samples),\n",
    "    'oldpeak': np.random.uniform(0, 6.2, n_samples),\n",
    "    'slope': np.random.choice([0, 1, 2], n_samples),\n",
    "    'ca': np.random.choice([0, 1, 2, 3], n_samples),\n",
    "    'thal': np.random.choice([1, 2, 3], n_samples),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "heart_disease_prob = (\n",
    "    0.1 + 0.15 * (df['age'] > 60) + 0.1 * (df['sex'] == 1) +\n",
    "    0.2 * (df['cp'] >= 2) + 0.15 * (df['trestbps'] > 140) +\n",
    "    0.15 * (df['chol'] > 240) + 0.1 * (df['exang'] == 1) +\n",
    "    0.15 * (df['oldpeak'] > 1.5) + 0.1 * (df['thalach'] < 120) +\n",
    "    np.random.normal(0, 0.1, n_samples)\n",
    ")\n",
    "df['target'] = (heart_disease_prob > 0.5).astype(int)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info and target distribution\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\n",
    "Target distribution:\")\n",
    "print(df['target'].value_counts(normalize=True))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['target'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Heart Disease Distribution')\n",
    "plt.xlabel('Target (0=No Disease, 1=Disease)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age groups and clinical thresholds\n",
    "df_processed = df.copy()\n",
    "df_processed['age_group'] = pd.cut(df_processed['age'], bins=[0, 40, 50, 60, 100], labels=['<40', '40-50', '50-60', '>60'])\n",
    "df_processed['high_bp'] = (df_processed['trestbps'] > 140).astype(int)\n",
    "df_processed['high_chol'] = (df_processed['chol'] > 240).astype(int)\n",
    "df_processed['low_hr'] = (df_processed['thalach'] < 120).astype(int)\n",
    "df_processed['high_st_depression'] = (df_processed['oldpeak'] > 1.5).astype(int)\n",
    "df_processed = pd.get_dummies(df_processed, columns=['cp', 'restecg', 'slope', 'thal', 'age_group'], drop_first=True)\n",
    "\n",
    "X = df_processed.drop('target', axis=1)\n",
    "y = df_processed['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "models['LR'] = (y_pred_lr, y_pred_proba_lr)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "models['RF'] = (y_pred_rf, y_pred_proba_rf)\n",
    "\n",
    "# SVM\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "y_pred_proba_svm = svm.predict_proba(X_test_scaled)[:, 1]\n",
    "models['SVM'] = (y_pred_svm, y_pred_proba_svm)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "y_pred_proba_gb = gb.predict_proba(X_test)[:, 1]\n",
    "models['GB'] = (y_pred_gb, y_pred_proba_gb)\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "for name, (y_pred, y_pred_proba) in models.items():\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba)\n",
    "    })\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "Key findings and clinical implications discussed in the tutorial."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
